{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GNN для предсказания band gap TMDC\n",
        "\n",
        "Демонстрация обучения модели на данных IDAO-2022.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from source.train import train_model, evaluate_model\n",
        "from source.graph import build_graph_from_structure\n",
        "from source.dataset import GraphListDataset\n",
        "import random\n",
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import json\n",
        "from pymatgen.core import Structure\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Загрузка конфигурации и подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 2076, Test size: 890\n"
          ]
        }
      ],
      "source": [
        "DATA_PATH = \"./data/dichalcogenides_public\"\n",
        "EWT_EPSILON = 0.1  # порог в эВ для Energy within Threshold\n",
        "\n",
        "def read_pymatgen_dict(file):\n",
        "    with open(file, \"r\") as f:\n",
        "        d = json.load(f)\n",
        "    return Structure.from_dict(d)\n",
        "\n",
        "def prepare_dataset(dataset_path, test_size=0.3, seed=600):\n",
        "    dataset_path = Path(dataset_path)\n",
        "    targets = pd.read_csv(dataset_path / \"targets.csv\", index_col=0).iloc[:, 0]\n",
        "    struct = {\n",
        "        item.stem: read_pymatgen_dict(item)\n",
        "        for item in (dataset_path / \"structures\").iterdir()\n",
        "        if item.suffix == \".json\"\n",
        "    }\n",
        "\n",
        "    data = pd.DataFrame({\"structures\": pd.Series(struct)})\n",
        "    data = data.join(targets.rename(\"targets\"))\n",
        "    data = data.dropna(subset=[\"targets\"])\n",
        "\n",
        "    return train_test_split(data, test_size=test_size, random_state=seed)\n",
        "\n",
        "train, test = prepare_dataset(DATA_PATH)\n",
        "print(f\"Train size: {len(train)}, Test size: {len(test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Преобразование структур в графы\n",
        "\n",
        "Создаем графы для каждого материала и формируем словарь `datasets` с train/val/test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dataframe_to_graphs(df, cutoff=4.0, rbf_dim=16):\n",
        "    graphs = []\n",
        "    for _, row in df.iterrows():\n",
        "        structure = row[\"structures\"]\n",
        "        target = row[\"targets\"]\n",
        "        target_val = float(np.asarray(target).reshape(-1)[0])\n",
        "        graph = build_graph_from_structure(structure, cutoff=cutoff, rbf_dim=rbf_dim)\n",
        "        graph.y = np.asarray([target_val], dtype=np.float32)\n",
        "        graphs.append(graph)\n",
        "    return GraphListDataset(graphs)\n",
        "\n",
        "rng = np.random.default_rng(42)\n",
        "indices = np.arange(len(train))\n",
        "rng.shuffle(indices)\n",
        "val_size = int(len(train) * 0.1)\n",
        "val_idx = indices[:val_size]\n",
        "train_idx = indices[val_size:]\n",
        "\n",
        "train_df = train.iloc[train_idx]\n",
        "val_df = train.iloc[val_idx]\n",
        "\n",
        "datasets = {\n",
        "    \"train\": dataframe_to_graphs(train_df),\n",
        "    \"val\": dataframe_to_graphs(val_df),\n",
        "    \"test\": dataframe_to_graphs(test),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Обучение модели\n",
        "\n",
        "Обучаем NumPy-реализацию GNN и сохраняем историю ошибок."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (191,128) (191,64) ",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m node_feat_dim = sample.x.shape[-\u001b[32m1\u001b[39m]\n\u001b[32m      3\u001b[39m edge_feat_dim = sample.edge_attr.shape[-\u001b[32m1\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model, history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mval\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnode_feat_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_feat_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43medge_feat_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_feat_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_clip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize_y\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mewt_epsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEWT_EPSILON\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Diosa\\Desktop\\Магистратура\\ФООСИИ\\6 GNN\\source\\train.py:100\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(train_dataset, val_dataset, node_feat_dim, edge_feat_dim, epochs, lr, weight_decay, batch_size, seed, grad_clip, hidden_dim, num_layers, normalize_y, verbose, ewt_epsilon)\u001b[39m\n\u001b[32m     98\u001b[39m     target = (target - model.y_mean) / model.y_std\n\u001b[32m     99\u001b[39m     grad = (\u001b[32m2.0\u001b[39m * (pred - target)) / \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m     batch_loss += \u001b[38;5;28mfloat\u001b[39m(np.mean((pred - target) ** \u001b[32m2\u001b[39m))\n\u001b[32m    102\u001b[39m model.clip_gradients(max_norm=grad_clip)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Diosa\\Desktop\\Магистратура\\ФООСИИ\\6 GNN\\source\\model.py:215\u001b[39m, in \u001b[36mTMDNet.backward\u001b[39m\u001b[34m(self, data, grad_out)\u001b[39m\n\u001b[32m    213\u001b[39m grad_h = np.repeat(grad / num_nodes, num_nodes, axis=\u001b[32m0\u001b[39m)\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m.layers):\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     grad_h = \u001b[43mlayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_h\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m pre_h = \u001b[38;5;28mself\u001b[39m._cache[\u001b[33m\"\u001b[39m\u001b[33mpre_h\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    218\u001b[39m grad_pre_h = grad_h * (pre_h > \u001b[32m0\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Diosa\\Desktop\\Магистратура\\ФООСИИ\\6 GNN\\source\\model.py:132\u001b[39m, in \u001b[36mMPNNLayer.backward\u001b[39m\u001b[34m(self, grad_out)\u001b[39m\n\u001b[32m    129\u001b[39m x_s = \u001b[38;5;28mself\u001b[39m._cache[\u001b[33m\"\u001b[39m\u001b[33mx_s\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    130\u001b[39m deg = \u001b[38;5;28mself\u001b[39m._cache[\u001b[33m\"\u001b[39m\u001b[33mdeg\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m grad_pre_out = \u001b[43mgrad_out\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_out\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m grad_x = \u001b[38;5;28mself\u001b[39m.w_self.backward(grad_pre_out)\n\u001b[32m    134\u001b[39m grad_x += grad_out\n",
            "\u001b[31mValueError\u001b[39m: operands could not be broadcast together with shapes (191,128) (191,64) "
          ]
        }
      ],
      "source": [
        "sample = datasets[\"train\"][0]\n",
        "node_feat_dim = sample.x.shape[-1]\n",
        "edge_feat_dim = sample.edge_attr.shape[-1]\n",
        "\n",
        "model, history = train_model(\n",
        "    train_dataset=datasets[\"train\"],\n",
        "    val_dataset=datasets[\"val\"],\n",
        "    node_feat_dim=node_feat_dim,\n",
        "    edge_feat_dim=edge_feat_dim,\n",
        "    epochs=8,\n",
        "    lr=5e-4,\n",
        "    batch_size=32,\n",
        "    hidden_dim=64,\n",
        "    num_layers=3,\n",
        "    grad_clip=0.5,\n",
        "    normalize_y=True,\n",
        "    ewt_epsilon=EWT_EPSILON,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Оценка и визуализация\n",
        "\n",
        "Считаем метрики на test (или val) и строим графики."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eval_dataset = datasets[\"test\"]\n",
        "if not hasattr(datasets[\"test\"][0], \"y\"):\n",
        "    print(\"Test split has no targets; evaluating on val split.\")\n",
        "    eval_dataset = datasets[\"val\"]\n",
        "\n",
        "test_loss, test_mae, test_ewt = evaluate_model(model, eval_dataset, ewt_epsilon=EWT_EPSILON)\n",
        "print(f\"Eval loss: {test_loss:.4f}, MAE: {test_mae:.4f}, EwT: {test_ewt:.3f}\")\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(history[\"train_loss\"], label=\"train_mse\")\n",
        "plt.plot(history[\"val_loss\"], label=\"val_mse\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
